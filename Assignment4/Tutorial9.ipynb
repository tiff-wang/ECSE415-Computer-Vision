{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE415 - Intro to Computer Vision\n",
    "## Tutorial 9 - Introduction to Machine Learning  using Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning problem consists of $n$ instances of data and attempts to predict properties of unseen data.\n",
    "\n",
    "Learning problems can be separated into several categories:\n",
    "* Supervised Learning: data comes with additional attributes that we want to predict. This problem can be either:\n",
    " * Classification: Samples belong to two or more classes and the algorithm learns from already labeled data to         predict to class of unseen data.\n",
    " * Regression: the desired output consists of one or more continuous variables.\n",
    "* Unsupervised Learning: data consists of a set of input vectors without any corresponding target values. Examples include clustering, density estimation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions: (1797, 64)\n",
      "Output data dimensions: (1797,)\n",
      "Input data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf24eccdd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output labels:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print(\"Input data dimensions:\", digits.data.shape)\n",
    "print(\"Output data dimensions:\", digits.target.shape)\n",
    "\n",
    "print(\"Input data:\")\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Output labels:\")\n",
    "print(digits.target[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict the output label (number from 0-9) for each input image. Since we are provided with examples of each of the 10 possible classes, we can now attempt to *fit* an estimator to be able to *predict* the classes to which unseen samples belong.\n",
    "\n",
    "We can begin by looking at a Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [0 8 9 8]\n",
      "Actual Label: [0 8 9 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAACGBJREFUeJzt3W1oXncZx/Hfbw7nw9a0bkNslRSdjsFg8cV8IyMFFSdMqL7QCZO2KMhAbKeyoaLNhoi+cEt8IT6SVOYD28TWvpjCsB2IyqZkRbsNdUtCS8ecmsRN58O2yxf3CdzOrOfKenLfucr3A4Gm58r//M/h9JfDuc/VvyNCAIA6zhn2BAAAa0NwA0AxBDcAFENwA0AxBDcAFENwA0AxBDeADcH212x/tuvas5F5jxvAerM9L+nVkp6R9KykByV9R9I3IuK5Mxx7h6TbI+K1g/zZYeKOG8CgvDsiLpA0KumLkm6S9O3hTqkmghvAQEXEckT8WNL7Je2yfbkk2Z6x/fmVOts32n7M9inbH7Ydti/pr7X9Skl3S9pq+6nma6vtt9j+te2/2X7c9q2Zudk+2oz7i2asw7YvtP3dZqz7bW/vq5+yfaLZ9hvbV/Vte7ntA7YXbT/UHM/Jvu1bbf/Q9hO252x/LHsOCW4AQxER90k6Kemq52+zfbWkj0t6u6RLJO14gTH+Luldkk5FxPnN1ylJU5KmImKTpDdIumMNU7tW0gclbWt+9peSpiW9StJDkvb31d4vaazZ9j1Jd9p+WbNtv6Ttkl4v6R2Srus7vnMkHZZ0rNnP2yTts/3OzAQJbgDDdEq90Hu+90majojjEfEPSRNrHPc/ki6xfVFEPBURv1rDz05HxCMRsaze3fwjEXFPRDwj6U5Jb14pjIjbI+IvEfFMRHxZ0nmSLu07hi9ExGJEnJT0lb59XCnp4oi4JSL+HRGPSvqmer80WhHcAIZpm6S/rvL3WyWd6Pv+xCo1p/MhSW+S9HDzeOOaNfzs431/fnqV789f+cb2J5vHIMu2lySNSLqo2Xy6YxhV7/HO0sqXpE+r9wFuq3PThwIAHbJ9pXrB/fNVNj8mqf9Nj9edZqj/ezUuIv4g6QPNI4n3SrrL9oXNo5VONM+zb1TvMcfxiHjO9qIkNyUrx/DgKsdwQtJcRLzxxeybO24AA2V7U3MH/AP1XsX77Spld0jaY/sy26+QdLp3th+XdKHtkb59XGf74uZVw6Xmr8/otcNVXKDe641PSDrX9uckberbfoekT9neYnubpI/2bbtP0pO2b2o+xHyJ7cubX2atCG4Ag3LY9pPq3W1+RtKtkvasVhgRd6v3TPiIpD9KWnlG/a9Vah+W9H1JjzaPHbZKulrScdtPqfdB5bUR8XTHx/NTST+R9HtJC5L+qf99HHKLeh++zkm6R9JdK/OPiGclXaPeB5tzkv4s6VvqPWppRQMOgA3P9mWSfifpvOZDwnJsX6/eL5DxMx2LO24AG5Lt99g+z/YWSV+SdLhSaNt+je232j7H9qWSPiHpR12MTXAD2Kg+IulPkh5Rr03++uFOZ81eKunrkp6U9DNJhyR9tYuBeVQCAMVwxw0AxRDcAFDMujTg2O7k+cvu3btba6anp1trjh07ltrf/Px8a01mTktLS601EeHWolV0dW43b97cWjMzM9Nas2PHjtT+tm/f3lqTOW8Zwz63mWOdmJhorXnggQdS+5ucnEzVdeHFnlupu/Pb1XWZGUfKnd9BX7vccQNAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABSzLv9XSVcv2mfmtry83FqTbWQYH2//3xa3bNnSWlOhASdzTq644orWmptvvjm1v0yzQ+a8VTi3mUau0dHRLnYlKfdvoKsGqPVuwMnMc25urrVmYWGhtSbTBCVJBw8ebK2hAQcAcFoENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUsy4r4GSMjY11Mk7mJfrsCiGZppSdO3e21mRX1himTHNNV40dUq5pInNuDx06lNrfesmsrJJprrnhhhtaa44ePZqYkTQ7O9tak1m5aZAr6byQTPNS5rrMrPCUvXYzc8rsr0vccQNAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABQztAacrl5Y77JpINOAk31pf6PLrFyzf//+1ppdu3al9pdpOBl2c03GyMhIJ+N01YCWlV0FqoLMNZdZtSZzfUvSgQMHUnWDxB03ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMUNrwMmsJDJomTllVtypYNArdpwtDSCZJqHMSj5TU1OtNRvx38hGkGnmyqySk7URm+644waAYghuACiG4AaAYghuACiG4AaAYghuACiG4AaAYghuACiG4AaAYobWOTk7O9vJOPv27WutyXY+jY6OttYsLi6mxtro9u7d21qzsLDQWpM5Z1JuKalBd3Oul0x3ZZfLtEVEa838/Hxn+1tPmW7R8fHx1po9e/a01mTPyZEjR1prdu/e3VozMzOT2l8Gd9wAUAzBDQDFENwAUAzBDQDFENwAUAzBDQDFENwAUAzBDQDFDK0B5957722tySw/dNttt3UxnbTMvCvInNtMQ0x2iaiRkZFU3dkg00QyNja2/hMpqKvl2jLjdNmUNOjlzbjjBoBiCG4AKIbgBoBiCG4AKIbgBoBiCG4AKIbgBoBiCG4AKGZoDThLS0utNZnVbaanp1trMiu5SNLExERrTWbeFWQaQDLnP9swMTk5mao7G2SajXbu3Nlak1npRco1hVVZAaer6yRzXWav3cz5HfT1zR03ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMQQ3ABRDcANAMY6IYc8BALAG3HEDQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDEENwAUQ3ADQDH/BdIgUeNLo/UNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf24d5bd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "# training, let's us all the data but the last 4 instances\n",
    "clf.fit(digits.data[:-4], digits.target[:-4])\n",
    "# now predict the label for the last 2 instances\n",
    "print(\"Predicted Label:\", clf.predict(digits.data[-4:]))\n",
    "print(\"Actual Label:\", digits.target[-4:])\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.subplot(141), plt.imshow(digits.data[-4].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(142), plt.imshow(digits.data[-3].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(143), plt.imshow(digits.data[-2].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(144), plt.imshow(digits.data[-1].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.title(\"Digits Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn also lets you save your best model to disk for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pk1')\n",
    "\n",
    "# load back the pickled model at a later time\n",
    "clf = joblib.load('filename.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also update and fine-tune hyper-parameters after the model has been constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel:\n",
      "\tPredicted Labels: [5 4 8 8 4 9 0 8 9 8]\n",
      "\tActual Labels:    [5 4 8 8 4 9 0 8 9 8]\n",
      "\n",
      "Radial Basis Function Kernel:\n",
      "\tPredicted Labels: [5 4 5 5 4 9 5 5 5 5]\n",
      "\tActual Labels:    [5 4 8 8 4 9 0 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "# classifer object\n",
    "clf = svm.SVC()\n",
    "# set hyper-parameters\n",
    "print(\"Linear Kernel:\")\n",
    "clf.set_params(kernel='linear').fit(digits.data[:-10], digits.target[:-10])\n",
    "print(\"\\tPredicted Labels:\", clf.predict(digits.data[-10:]))\n",
    "print(\"\\tActual Labels:   \", digits.target[-10:])\n",
    "print(\"\")\n",
    "\n",
    "print(\"Radial Basis Function Kernel:\")\n",
    "clf.set_params(kernel='rbf').fit(digits.data[:-10], digits.target[:-10])\n",
    "print(\"\\tPredicted Labels:\", clf.predict(digits.data[-10:]))\n",
    "print(\"\\tActual Labels:   \", digits.target[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn also supports multiclass and mutlilabel fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 3, 4, 9, 0, 3, 9, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train = digits.data[:-10]\n",
    "y_train = digits.target[:-10]\n",
    "X_test = digits.data[-10:]\n",
    "y_test = digits.target[-10:]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator = SVC(random_state=0))\n",
    "classif.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the above case, the classifier is fit on a 1d array of multiclass labels and the **predict()** method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_binary = LabelBinarizer().fit_transform(y_train)\n",
    "classif.fit(X_train, y_train_binary).predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the classifier is **fit()** on a 2d binary representation of **y** using the **LabelBinarizer**. In this case **predict()** returns a 2d array representing the corresponding multilabel predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the classifier is fit upon instances each assigned multiple labels. The **MultiLabelBinarizer** is used to binarize the 2d array of multilabels to **fit** upon. As a result, **predict()** returns a 2d array with multiple predicted labels for each instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
